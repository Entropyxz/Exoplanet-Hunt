{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1520709d-67ea-462e-aab1-eb2198497cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LABEL   FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6  FLUX.7  \\\n",
      "0      2    93.85    83.81    20.10   -26.98   -39.56  -124.71 -135.18   \n",
      "1      2   -38.88   -33.83   -58.54   -40.09   -79.31   -72.81  -86.55   \n",
      "2      2   532.64   535.92   513.73   496.92   456.45   466.00  464.50   \n",
      "3      2   326.52   347.39   302.35   298.13   317.74   312.70  322.33   \n",
      "4      2 -1107.21 -1112.59 -1118.95 -1095.10 -1057.55 -1034.48 -998.34   \n",
      "\n",
      "    FLUX.8  FLUX.9  ...  FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
      "0   -96.27  -79.89  ...     -78.07    -102.15    -102.15      25.13   \n",
      "1   -85.33  -83.97  ...      -3.28     -32.21     -32.21     -24.89   \n",
      "2   486.39  436.56  ...     -71.69      13.31      13.31     -29.89   \n",
      "3   311.31  312.42  ...       5.71      -3.73      -3.73      30.05   \n",
      "4 -1022.71 -989.57  ...    -594.37    -401.66    -401.66    -357.24   \n",
      "\n",
      "   FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
      "0      48.57      92.54      39.32      61.42       5.08     -39.54  \n",
      "1      -4.86       0.76     -11.70       6.46      16.00      19.93  \n",
      "2     -20.88       5.06     -11.80     -28.91     -70.02     -96.67  \n",
      "3      20.03     -12.67      -8.77     -17.31     -17.35      13.98  \n",
      "4    -443.76    -438.54    -399.71    -384.65    -411.79    -510.54  \n",
      "\n",
      "[5 rows x 3198 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5087 entries, 0 to 5086\n",
      "Columns: 3198 entries, LABEL to FLUX.3197\n",
      "dtypes: float64(3197), int64(1)\n",
      "memory usage: 124.1 MB\n",
      "None\n",
      "Balanced features: (9806, 42), Balanced labels: (9806,)\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Data Loading & Preprocessing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.combine import SMOTEENN\n",
    "import warnings\n",
    "\n",
    "# Suppress TensorFlow and XGBoost warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"tensorflow\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"xgboost\")\n",
    "\n",
    "# Load the training and testing data\n",
    "train_data = pd.read_csv('exoTrain.csv')\n",
    "test_data = pd.read_csv('exoTest.csv')\n",
    "\n",
    "print(train_data.head())\n",
    "print(train_data.info())\n",
    "\n",
    "# 1. Scale data (assuming first column is LABEL)\n",
    "scaler = StandardScaler()\n",
    "train_data_scaled = train_data.copy()\n",
    "train_data_scaled.iloc[:, 1:] = scaler.fit_transform(train_data.iloc[:, 1:])\n",
    "test_data_scaled = test_data.copy()\n",
    "test_data_scaled.iloc[:, 1:] = scaler.transform(test_data.iloc[:, 1:])\n",
    "\n",
    "# 2. Handle outliers\n",
    "def handle_outliers(data):\n",
    "    for column in data.columns[1:]:\n",
    "        data_column = data[column]\n",
    "        median, std = data_column.median(), data_column.std()\n",
    "        outliers = (data_column - median).abs() > 3 * std\n",
    "        data.loc[outliers, column] = np.sign(data_column[outliers]) * 3 * std + median\n",
    "    return data\n",
    "\n",
    "train_data_scaled = handle_outliers(train_data_scaled)\n",
    "test_data_scaled = handle_outliers(test_data_scaled)\n",
    "\n",
    "# 3. PCA: Reduce dimensions (preserve 95% variance)\n",
    "pca = PCA(n_components=0.95)\n",
    "train_data_pca = pca.fit_transform(train_data_scaled.iloc[:, 1:])\n",
    "test_data_pca = pca.transform(test_data_scaled.iloc[:, 1:])\n",
    "\n",
    "# 4. Balance data using SMOTEENN\n",
    "X_train = train_data_pca\n",
    "y_train = train_data['LABEL'] - 1  # Convert LABEL to 0/1\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote_enn.fit_resample(X_train, y_train)\n",
    "print(f\"Balanced features: {X_train_balanced.shape}, Balanced labels: {np.array(y_train_balanced).shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24e0930c-9c2c-4069-8850-47cfe153eb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       565\n",
      "           1       0.33      0.20      0.25         5\n",
      "\n",
      "    accuracy                           0.99       570\n",
      "   macro avg       0.66      0.60      0.62       570\n",
      "weighted avg       0.99      0.99      0.99       570\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Logistic Regression Baseline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve, classification_report\n",
    "\n",
    "y_test = test_data['LABEL'] - 1  # Convert LABEL to 0/1\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=2000, class_weight='balanced', random_state=42)\n",
    "log_reg.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "y_proba = log_reg.predict_proba(test_data_pca)[:, 1]\n",
    "precision_lr, recall_lr, thresholds_lr = precision_recall_curve(y_test, y_proba)\n",
    "f1_scores_lr = (2 * precision_lr[:-1] * recall_lr[:-1]) / (precision_lr[:-1] + recall_lr[:-1] + 1e-9)\n",
    "optimal_idx_lr = np.argmax(f1_scores_lr)\n",
    "best_threshold_lr = thresholds_lr[optimal_idx_lr]\n",
    "\n",
    "y_pred_lr = (y_proba >= best_threshold_lr).astype(int)\n",
    "print(\"Logistic Regression Results:\")\n",
    "print(classification_report(y_test, y_pred_lr, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bfa6df3-2616-439f-a1a7-4cd1b333eaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes in y_train_balanced: [0 1]\n",
      "Epoch 1/100\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5084 - loss: 5.5026 - precision: 0.5145 - recall: 0.9088 - val_accuracy: 0.5148 - val_loss: 2.3105 - val_precision: 0.5148 - val_recall: 1.0000\n",
      "Epoch 2/100\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5149 - loss: 2.6886 - precision: 0.5144 - recall: 0.9999 - val_accuracy: 0.5173 - val_loss: 1.7958 - val_precision: 0.5161 - val_recall: 1.0000\n",
      "Epoch 3/100\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5243 - loss: 2.2412 - precision: 0.5221 - recall: 1.0000 - val_accuracy: 0.5194 - val_loss: 1.6067 - val_precision: 0.5172 - val_recall: 1.0000\n",
      "Epoch 4/100\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5229 - loss: 2.0609 - precision: 0.5195 - recall: 1.0000 - val_accuracy: 0.5219 - val_loss: 1.5168 - val_precision: 0.5185 - val_recall: 1.0000\n",
      "Epoch 5/100\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5236 - loss: 1.9878 - precision: 0.5214 - recall: 1.0000 - val_accuracy: 0.5240 - val_loss: 1.4259 - val_precision: 0.5195 - val_recall: 1.0000\n",
      "Epoch 6/100\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5199 - loss: 1.9231 - precision: 0.5167 - recall: 1.0000 - val_accuracy: 0.5214 - val_loss: 1.4111 - val_precision: 0.5182 - val_recall: 1.0000\n",
      "Epoch 7/100\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5224 - loss: 1.8931 - precision: 0.5194 - recall: 1.0000 - val_accuracy: 0.5209 - val_loss: 1.4117 - val_precision: 0.5179 - val_recall: 1.0000\n",
      "Epoch 8/100\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5244 - loss: 1.8685 - precision: 0.5216 - recall: 1.0000 - val_accuracy: 0.5189 - val_loss: 1.4347 - val_precision: 0.5169 - val_recall: 1.0000\n",
      "Epoch 9/100\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5158 - loss: 1.8813 - precision: 0.5133 - recall: 1.0000 - val_accuracy: 0.5194 - val_loss: 1.3935 - val_precision: 0.5172 - val_recall: 1.0000\n",
      "Epoch 10/100\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5170 - loss: 1.8620 - precision: 0.5146 - recall: 1.0000 - val_accuracy: 0.5189 - val_loss: 1.3943 - val_precision: 0.5169 - val_recall: 1.0000\n",
      "Epoch 11/100\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5248 - loss: 1.8303 - precision: 0.5221 - recall: 1.0000 - val_accuracy: 0.5183 - val_loss: 1.4008 - val_precision: 0.5166 - val_recall: 1.0000\n",
      "Epoch 12/100\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5125 - loss: 1.8627 - precision: 0.5105 - recall: 1.0000 - val_accuracy: 0.5183 - val_loss: 1.4115 - val_precision: 0.5166 - val_recall: 1.0000\n",
      "Epoch 13/100\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5198 - loss: 1.8464 - precision: 0.5177 - recall: 1.0000 - val_accuracy: 0.5199 - val_loss: 1.3961 - val_precision: 0.5174 - val_recall: 1.0000\n",
      "Epoch 14/100\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5276 - loss: 1.8246 - precision: 0.5246 - recall: 1.0000 - val_accuracy: 0.5199 - val_loss: 1.3435 - val_precision: 0.5174 - val_recall: 1.0000\n",
      "Epoch 15/100\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5213 - loss: 1.8444 - precision: 0.5189 - recall: 1.0000 - val_accuracy: 0.5199 - val_loss: 1.3999 - val_precision: 0.5174 - val_recall: 1.0000\n",
      "Epoch 16/100\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5169 - loss: 1.8390 - precision: 0.5142 - recall: 1.0000 - val_accuracy: 0.5224 - val_loss: 1.3156 - val_precision: 0.5187 - val_recall: 1.0000\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Optimal threshold for NN: 0.9299\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\n",
      "Neural Network Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.77      0.87       565\n",
      "           1       0.02      0.60      0.04         5\n",
      "\n",
      "    accuracy                           0.77       570\n",
      "   macro avg       0.51      0.68      0.46       570\n",
      "weighted avg       0.99      0.77      0.86       570\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Neural Network Model & Evaluation\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import precision_recall_curve, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"Unique classes in y_train_balanced:\", np.unique(y_train_balanced))\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train_balanced.shape[1],)),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.02)),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu', kernel_regularizer=l2(0.02)),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_recall',\n",
    "    patience=15,\n",
    "    mode='max',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "    X_train_balanced, y_train_balanced,\n",
    "    test_size=0.2,\n",
    "    stratify=y_train_balanced,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "y_train_final = np.array(y_train_final)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "class_weight = {0: 1, 1: 15}\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_final, y_train_final,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stop],\n",
    "    class_weight=class_weight,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "val_proba = model.predict(X_val).flatten()\n",
    "precision_nn, recall_nn, thresholds_nn = precision_recall_curve(y_val, val_proba)\n",
    "f1_scores_nn = (2 * precision_nn[:-1] * recall_nn[:-1]) / (precision_nn[:-1] + recall_nn[:-1] + 1e-9)\n",
    "best_threshold_nn = thresholds_nn[np.argmax(f1_scores_nn)]\n",
    "print(f\"Optimal threshold for NN: {best_threshold_nn:.4f}\")\n",
    "\n",
    "nn_proba = model.predict(test_data_pca).flatten()\n",
    "y_pred_nn = (nn_proba >= best_threshold_nn).astype(int)\n",
    "print(\"\\nNeural Network Results:\")\n",
    "print(classification_report(y_test, y_pred_nn, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee440a8d-d883-4b07-b835-2e2023bf867f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale_pos_weight: 0.942936397860115\n",
      "Optimal threshold for XGB: 0.35649315\n",
      "XGBoost Model Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       565\n",
      "           1       0.33      0.20      0.25         5\n",
      "\n",
      "    accuracy                           0.99       570\n",
      "   macro avg       0.66      0.60      0.62       570\n",
      "weighted avg       0.99      0.99      0.99       570\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: XGBoost Model & Evaluation\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import precision_recall_curve, classification_report\n",
    "\n",
    "# Compute scale_pos_weight for imbalanced data\n",
    "neg_count = np.sum(np.array(y_train_balanced) == 0)\n",
    "pos_count = np.sum(np.array(y_train_balanced) == 1)\n",
    "scale_pos_weight = neg_count / pos_count\n",
    "print(\"Scale_pos_weight:\", scale_pos_weight)\n",
    "\n",
    "# Initialize XGBClassifier without using the \"use_label_encoder\" parameter\n",
    "xgb_model = XGBClassifier(\n",
    "    random_state=42,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "xgb_proba = xgb_model.predict_proba(test_data_pca)[:, 1]\n",
    "precision_xgb, recall_xgb, thresholds_xgb = precision_recall_curve(y_test, xgb_proba)\n",
    "f1_scores_xgb = (2 * precision_xgb[:-1] * recall_xgb[:-1]) / (precision_xgb[:-1] + recall_xgb[:-1] + 1e-9)\n",
    "optimal_idx_xgb = np.argmax(f1_scores_xgb)\n",
    "best_threshold_xgb = thresholds_xgb[optimal_idx_xgb]\n",
    "print(\"Optimal threshold for XGB:\", best_threshold_xgb)\n",
    "\n",
    "y_pred_xgb = (xgb_proba >= best_threshold_xgb).astype(int)\n",
    "print(\"XGBoost Model Results:\")\n",
    "print(classification_report(y_test, y_pred_xgb, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f699e41d-2343-42d9-be8c-99d9a1151a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold for RF: 0.395\n",
      "Random Forest Model Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       565\n",
      "           1       1.00      0.20      0.33         5\n",
      "\n",
      "    accuracy                           0.99       570\n",
      "   macro avg       1.00      0.60      0.66       570\n",
      "weighted avg       0.99      0.99      0.99       570\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Random Forest Model & Evaluation\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve, classification_report\n",
    "\n",
    "# Initialize the RandomForestClassifier with balanced class weights\n",
    "rf_model = RandomForestClassifier(n_estimators=200, \n",
    "                                  class_weight='balanced',\n",
    "                                  random_state=42)\n",
    "\n",
    "# Train on the balanced training data\n",
    "rf_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Predict probabilities on the test data\n",
    "rf_proba = rf_model.predict_proba(test_data_pca)[:, 1]\n",
    "\n",
    "# Generate the precision-recall curve and compute F1-scores for threshold optimization\n",
    "precision_rf, recall_rf, thresholds_rf = precision_recall_curve(y_test, rf_proba)\n",
    "# Note: thresholds_rf has one less element than precision_rf and recall_rf.\n",
    "f1_scores_rf = (2 * precision_rf[:-1] * recall_rf[:-1]) / (precision_rf[:-1] + recall_rf[:-1] + 1e-9)\n",
    "optimal_idx_rf = np.argmax(f1_scores_rf)\n",
    "best_threshold_rf = thresholds_rf[optimal_idx_rf]\n",
    "print(\"Optimal threshold for RF:\", best_threshold_rf)\n",
    "\n",
    "# Apply the optimal threshold to get binary predictions\n",
    "y_pred_rf = (rf_proba >= best_threshold_rf).astype(int)\n",
    "\n",
    "# Display the classification report\n",
    "print(\"Random Forest Model Results:\")\n",
    "print(classification_report(y_test, y_pred_rf, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2069ba-265c-46c9-81b5-c70534917597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
